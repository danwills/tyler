# Tyler

It's name is a play on 'tiler', the idea being that you load a bunch of tilable images into it. And vaguely the chaos of Tyler Durden (from Fight Club).

This is a project that I started a rather long time ago, probably in 1999 or something.. it began from trying to implement a simple neural-net for a Cognitive Science assignment at Adelaide University. Didn't get very far past a very-prototype phase with the neural-net but learnt a lot about Java, and for me that unlocked some 2d-image-pixel flexibilities that eventually made Tyler happen.

The main idea that I think is interesting about this whole engine, is how it explores the idea of a pixel (or particle) having a 'neighborhood' or set of input pixels or values. Both pixels and particles can be set to update their state by sampling their neighborhood (or rule data) and then following some function as to what to do with that information. It's an idea that is present, partially explored, but not yet hugely well developed in Tyler.

On the pixel side, a simple list-of-neighbours format supports two seemingly different types of image processing, warping (or ~advection) and filtering (like blur/sharpen/edge-detect/game-of-life/reaction-diffusion [1]): 

1) A two-dimensional warp-field such as a 2d curlnoise, or warps generated by fractal functions (interestingly, these produce fractals when run in feedback), noise or radial/metaball twist-radial-warp functions. With these generators, the idea is that multiple neighbours are only used to increase the sampling fidelity (anti-aliasing), not to cater for any intentional focal/frequency-space shift.

2) Multi-neighbour neighborhoods, intended to be fed into 'filter'-like processes. Essentially, you could think of these as working in frequency-space or somehow forming a spatially-defined algorithm such as blurring/sharpening, or diffusing. Simple examples are the Von-Neumann neighborhood (shaped like a plus, all the edge-neighbors in a grid network) or Moore (N/NE/E/SE/S/SW/W/NW, all vertex-neighbors).

These days (2019 eh) I'm still interested in this model of processing and I'm thinking that if I added to it a 'weight' or float value per-neighbour (where each neighbour was just an integer index previously), that would make the output potentially much more presentable (ie, properly filtered). Maybe adding a couple of floats, and treating the values as complex, would be interesting too.)

I'd also like to explore out towards sub-neuralnet levels of connectivity in terms of numbers of neighbours. Under that scheme a pixel can potentially be connected to all other pixels, at a given weight (or complex-weight).. which sounds to me like it could be used to make an image that is able to make changes to itself (for a given rule) in space, in frequency-space and even in arbitrarily-connected-network-space (whatever that's actually called). Sounds like difficult-to-explore fun to me!

I've always been a massive fan of the demoscene (and realtime-graphics generally: [2]) and some of the ideas in Tyler are intended to be realtime effects such that you might use in fairly tight control-synchronisation in a VJing or demo-engine scenario. (That is why the filtering strategy is low-fi, but it's fast!). I did a couple of VJing gigs using Tyler a fair while ago, but obviously that didn't turn into a profession.

So, what can we do with Tyler? (for fun or experimentation!)

* Tab or Right-click menu to access pretty much all actions, help and heaps of hotkeys, eg. hold Ctrl+Alt+Shift to move the menu around.
* Full capture of 'vector' particles and UI components into the pixel-automata realm (can be disabled for speed too).
* 2D Particles emitted from the mouse pointer, with quite intricate ways to control their size/motion/draw-method and color evolution/alpha blending.
* Realtime pixel-feedback engine with various interesting ways to generate a warp or neighborhood for the feedback, including various fractals, noise, sines and an 11x11 boolean-matrix-based neighborhood generator.
* Complex (too complex? mostly useless) color/LUT-based transformation/color blending methods for advancing the pixel-automata iterations with.
* Idea of extracting a LUT from the image using a 'Tool' (along a line using a default extractor channel) and being able to then also edit and smooth the LUT values and use them in other parts of tyler (such as the pixel-neighbourhood-transfer-function and the particle color blend methods).

It's basically a particles and pixels playground, and I still think it's a fun thing to tinker with! : )

I have had some flickering issues with builds on some JDKs, but I think some recent commits hopefully fixes that.

Anyone interested in adapting this code to run on Android and make it into a fast (glsl) fun pixel playground, or just to port it as-is in all its software-rendering-glory please contact me: gdanzo at gmail.com

[1] Exact 'Game of Life' dynamics probably isn't easy to come by in Tyler, and neither is the behaviour of any specific reaction-diffusion system, but I think in principle both should be possible, and obviously trivially easy if you made source changes to directly support them in the engine.
[2] Do yourself a favour and watch some recent DemoScene Demos (from a recent platform such as windows). Groups to look for (amongst many more): CNCD, Fairlight, Orange, Kewlers, MFX, Conspiracy, Farbrausch, Quite, Satori, ASD.
